{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84d1054-26a5-428b-bae2-cc8f03d09c1f",
   "metadata": {},
   "source": [
    " **this code is proper only does not calculate distance**\n",
    " the distance cannot be calculated in webcam is because of the resolution of the webcam when we use pre recorded videos this is able to calculate the ditance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059b9e12-7882-4be1-83df-5470d4291474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "Data saved to detection_data.csv\n",
      "Data saved to detection_data.xlsx\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18296\\3325666788.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mim_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mim_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmax\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mim_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mymax\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mim_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[0mFONT_SCALE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[0mTHICKNESS_SCALE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     cv2.rectangle(\n\u001b[0;32m    215\u001b[0m         \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n",
      "KML file saved: real_time_detections.kml\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import simplekml\n",
    "import os\n",
    "\n",
    "# Load the optimized MobileNet model\n",
    "model = hub.load(\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\").signatures[\"default\"]\n",
    "\n",
    "# Initialize a dictionary to store color codes\n",
    "colorcodes = {}\n",
    "\n",
    "# Define some real-world object heights for estimation (in meters)\n",
    "object_heights = {\n",
    "    'Person': 1.7,  # Average height of a person in meters\n",
    "    'Vehicle': 1.5, # Approximate height of a vehicle\n",
    "    'Bird': 0.3,    # Average height of a bird\n",
    "    'Airplane': 3.0,# Approximate height of an airplane (from ground)\n",
    "    'Drone' : 3.0 \n",
    "}\n",
    "\n",
    "# Focal length (in pixels). This can vary depending on the camera.\n",
    "focal_length = 800  \n",
    "\n",
    "# Known reference points (top-left and bottom-right GPS coordinates)\n",
    "reference_points = {\n",
    "    'top_left': {'lat': 40.712776, 'lon': -74.005974, 'pixel': (0, 0)},\n",
    "    'bottom_right': {'lat': 40.703776, 'lon': -73.995974, 'pixel': (1280, 720)}\n",
    "}\n",
    "\n",
    "# Function to calculate the distance to an object using the pinhole camera model\n",
    "def calculate_distance(object_height, perceived_height):\n",
    "    if perceived_height > 0:\n",
    "        return (focal_length * object_height) / perceived_height\n",
    "    return None  # Return None if the height is 0 to avoid division by zero\n",
    "\n",
    "# Function to convert pixel coordinates to GPS coordinates\n",
    "def pixel_to_gps(pixel_x, pixel_y, ref_points, img_width, img_height):\n",
    "    lat_proportion = pixel_y / img_height\n",
    "    lon_proportion = pixel_x / img_width\n",
    "\n",
    "    lat = ref_points['top_left']['lat'] + lat_proportion * (ref_points['bottom_right']['lat'] - ref_points['top_left']['lat'])\n",
    "    lon = ref_points['top_left']['lon'] + lon_proportion * (ref_points['bottom_right']['lon'] - ref_points['top_left']['lon'])\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "# Function to draw bounding boxes and distances\n",
    "def drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color, distance=None):\n",
    "    im_height, im_width, _ = image.shape\n",
    "    left, top, right, bottom = int(xmin * im_width), int(ymin * im_height), int(xmax * im_width), int(ymax * im_height)\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), color=color, thickness=2)\n",
    "\n",
    "    FONT_SCALE = 0.5\n",
    "    THICKNESS_SCALE = 1\n",
    "\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (left, top - int(20)),\n",
    "        (right, top),\n",
    "        color=color,\n",
    "        thickness=-1\n",
    "    )\n",
    "\n",
    "    label = namewithscore\n",
    "    if distance is not None:\n",
    "        label += f\" Dist: {distance:.2f}m\"\n",
    "\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        label,\n",
    "        (left, top - int(5)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=FONT_SCALE,\n",
    "        thickness=THICKNESS_SCALE,\n",
    "        color=(255, 255, 255)\n",
    "    )\n",
    "\n",
    "# Function to process detections and draw them on the image\n",
    "def draw(image, boxes, classnames, scores, img_width, img_height):\n",
    "    boxesidx = tf.image.non_max_suppression(boxes, scores, max_output_size=10, iou_threshold=0.4, score_threshold=0.3)\n",
    "    detections = []\n",
    "\n",
    "    for i in boxesidx:\n",
    "        ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "        classname = classnames[i].decode(\"ascii\")\n",
    "        score = scores[i]\n",
    "        height_in_pixels = ymax - ymin\n",
    "\n",
    "        object_height = object_heights.get(classname.capitalize(), None)\n",
    "        distance = None\n",
    "\n",
    "        if object_height is not None:\n",
    "            perceived_height = height_in_pixels * img_height\n",
    "            distance = calculate_distance(object_height, perceived_height)\n",
    "\n",
    "        left, top, right, bottom = int(xmin * img_width), int(ymin * img_height), int(xmax * img_width), int(ymax * img_height)\n",
    "        gps_coords = pixel_to_gps((left + right) / 2, (top + bottom) / 2, reference_points, img_width, img_height)\n",
    "\n",
    "        detections.append((classname, score, distance, gps_coords))\n",
    "\n",
    "        if classname in colorcodes.keys():\n",
    "            color = colorcodes[classname]\n",
    "        else:\n",
    "            c1 = random.randrange(0, 255, 30)\n",
    "            c2 = random.randrange(0, 255, 25)\n",
    "            c3 = random.randrange(0, 255, 50)\n",
    "            colorcodes.update({classname: (c1, c2, c3)})\n",
    "            color = colorcodes[classname]\n",
    "\n",
    "        namewithscore = \"{}:{}\".format(classname, int(100 * score))\n",
    "        drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color, distance)\n",
    "\n",
    "    return image, detections\n",
    "\n",
    "# Function to generate KML file for Google Earth\n",
    "def generate_kml(detections, kml_filename=\"real_time_detections.kml\"):\n",
    "    kml = simplekml.Kml()\n",
    "    for classname, score, distance, gps_coords in detections:\n",
    "        if gps_coords:\n",
    "            lat, lon = gps_coords\n",
    "            description = f\"Class: {classname}\\nScore: {score:.2f}\\nDistance: {distance:.2f} meters\" if distance else f\"Class: {classname}\\nScore: {score:.2f}\\nDistance: N/A\"\n",
    "            pnt = kml.newpoint(name=classname, coords=[(lon, lat)])\n",
    "            pnt.description = description\n",
    "            pnt.style.labelstyle.color = simplekml.Color.red\n",
    "            pnt.style.labelstyle.scale = 1\n",
    "    kml.save(kml_filename)\n",
    "    print(f\"KML file saved: {kml_filename}\")\n",
    "\n",
    "# Thread function to periodically update Google Earth KML file\n",
    "def update_kml_periodically(interval, detections):\n",
    "    while True:\n",
    "        generate_kml(detections)\n",
    "        time.sleep(interval)  # Adjust the refresh interval as needed\n",
    "\n",
    "# Initialize webcam input\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Time\", \"Class\", \"Score\", \"Distance (m)\", \"GPS Coordinates (lat, lon)\", \"Latitude\", \"Longitude\", \"Name\", \"Description\"])\n",
    "\n",
    "try:\n",
    "    frame_count = 0\n",
    "    detections = []\n",
    "    \n",
    "    # Start a separate thread for real-time KML updates\n",
    "    kml_thread = threading.Thread(target=update_kml_periodically, args=(5, detections))  # Refresh KML every 5 seconds\n",
    "    kml_thread.daemon = True  # Daemon thread will stop when the main program ends\n",
    "    kml_thread.start()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        start_time = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 3 != 0:\n",
    "            continue\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        converted_img = tf.image.convert_image_dtype(frame_rgb, tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "        detection = model(converted_img)\n",
    "        result = {key: value.numpy() for key, value in detection.items()}\n",
    "\n",
    "        frame_with_boxes, detections = draw(frame, result['detection_boxes'], result['detection_class_entities'], result[\"detection_scores\"], original_width, original_height)\n",
    "\n",
    "        cv2.imshow('Video Object Detection', cv2.resize(frame_with_boxes, (original_width, original_height)))\n",
    "\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        if detections:\n",
    "            for classname, score, distance, gps_coords in detections:\n",
    "                lat, lon = gps_coords\n",
    "                name = f\"{classname} {int(100 * score)}%\"\n",
    "                description = f\"Detected {classname} with score {score:.2f}. Distance: {distance:.2f} meters\" if distance else f\"Detected {classname} with score {score:.2f}. Distance: N/A\"\n",
    "                \n",
    "                # Append the detection to the DataFrame in Google Earth compatible format\n",
    "                new_row = {\"Time\": current_time, \"Class\": classname, \"Score\": score, \"Distance (m)\": distance, \"GPS Coordinates (lat, lon)\": gps_coords, \"Latitude\": lat, \"Longitude\": lon, \"Name\": name, \"Description\": description}\n",
    "                df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time < 0.1:\n",
    "            time.sleep(0.1 - elapsed_time)\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the final DataFrame to CSV (delimited) format for Google Earth compatibility\n",
    "    output_csv_file = \"detection_data.csv\"\n",
    "    df.to_csv(output_csv_file, index=False)\n",
    "    print(f\"Data saved to {output_csv_file}\")\n",
    "\n",
    "    # Optionally, also save to Excel format\n",
    "    output_excel_file = \"detection_data.xlsx\"\n",
    "    df.to_excel(output_excel_file, index=False)\n",
    "    print(f\"Data saved to {output_excel_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d473fad-f533-443c-b493-6dfb6a4cd2de",
   "metadata": {},
   "source": [
    "** Test **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1debd96b-be31-4f1e-9f1f-5a80903c9a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "C:\\Users\\Sami\\AppData\\Local\\Temp\\ipykernel_10104\\187529918.py:175: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_rows], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detections saved to detections_with_gps.xlsx\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import random\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Load the optimized MobileNet model\n",
    "model = hub.load(\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\").signatures[\"default\"]\n",
    "\n",
    "# Initialize a dictionary to store color codes\n",
    "colorcodes = {}\n",
    "\n",
    "# Define some real-world object heights for estimation (in meters)\n",
    "object_heights = {\n",
    "    'Person': 1.7,  # Average height of a person in meters\n",
    "    'Vehicle': 1.5, # Approximate height of a vehicle\n",
    "    'Bird': 0.3,    # Average height of a bird\n",
    "    'Airplane': 3.0,# Approximate height of an airplane (from ground)\n",
    "    'Drone' : 3.0 \n",
    "}\n",
    "\n",
    "# Focal length (in pixels). This can vary depending on the camera.\n",
    "# Example: 800 pixels for a general camera, but you may need to calibrate this.\n",
    "focal_length = 800  \n",
    "\n",
    "# Known reference points (top-left and bottom-right GPS coordinates)\n",
    "reference_points = {\n",
    "    'top_left': {'lat': 40.712776, 'lon': -74.005974, 'pixel': (0, 0)},\n",
    "    'bottom_right': {'lat': 40.703776, 'lon': -73.995974, 'pixel': (1280, 720)}\n",
    "}\n",
    "\n",
    "# Function to calculate the distance to an object using the pinhole camera model\n",
    "def calculate_distance(object_height, perceived_height):\n",
    "    if perceived_height > 0:\n",
    "        return (focal_length * object_height) / perceived_height\n",
    "    return None  # Return None if the height is 0 to avoid division by zero\n",
    "\n",
    "# Function to convert pixel coordinates to GPS coordinates\n",
    "def pixel_to_gps(pixel_x, pixel_y, ref_points, img_width, img_height):\n",
    "    # Get the proportion of the pixel position in the image\n",
    "    lat_proportion = pixel_y / img_height\n",
    "    lon_proportion = pixel_x / img_width\n",
    "\n",
    "    # Calculate the latitude and longitude using linear interpolation\n",
    "    lat = ref_points['top_left']['lat'] + lat_proportion * (ref_points['bottom_right']['lat'] - ref_points['top_left']['lat'])\n",
    "    lon = ref_points['top_left']['lon'] + lon_proportion * (ref_points['bottom_right']['lon'] - ref_points['top_left']['lon'])\n",
    "\n",
    "    return lat, lon\n",
    "\n",
    "# Function to draw bounding boxes and distances\n",
    "def drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color, distance=None):\n",
    "    im_height, im_width, _ = image.shape\n",
    "    left, top, right, bottom = int(xmin * im_width), int(ymin * im_height), int(xmax * im_width), int(ymax * im_height)\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), color=color, thickness=2)\n",
    "\n",
    "    FONT_SCALE = 0.5\n",
    "    THICKNESS_SCALE = 1\n",
    "\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (left, top - int(20)),\n",
    "        (right, top),\n",
    "        color=color,\n",
    "        thickness=-1\n",
    "    )\n",
    "\n",
    "    label = namewithscore\n",
    "    if distance is not None:\n",
    "        label += f\" Dist: {distance:.2f}m\"\n",
    "\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        label,\n",
    "        (left, top - int(5)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=FONT_SCALE,\n",
    "        thickness=THICKNESS_SCALE,\n",
    "        color=(255, 255, 255)\n",
    "    )\n",
    "\n",
    "# Function to process detections and draw them on the image\n",
    "def draw(image, boxes, classnames, scores, img_width, img_height):\n",
    "    # Filter detections based on scores\n",
    "    boxesidx = tf.image.non_max_suppression(boxes, scores, max_output_size=10, iou_threshold=0.4, score_threshold=0.3)\n",
    "    detections = []\n",
    "\n",
    "    for i in boxesidx:\n",
    "        ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "        classname = classnames[i].decode(\"ascii\")\n",
    "        score = scores[i]\n",
    "        height_in_pixels = ymax - ymin  # Perceived height of the object in image space\n",
    "\n",
    "        # Get the real-world height of the object if known\n",
    "        object_height = object_heights.get(classname.capitalize(), None)\n",
    "        distance = None\n",
    "\n",
    "        if object_height is not None:\n",
    "            perceived_height = height_in_pixels * img_height  # Height of the bounding box in pixels\n",
    "            distance = calculate_distance(object_height, perceived_height)\n",
    "\n",
    "        # Calculate pixel coordinates and convert to GPS coordinates\n",
    "        left, top, right, bottom = int(xmin * img_width), int(ymin * img_height), int(xmax * img_width), int(ymax * img_height)\n",
    "        gps_coords = pixel_to_gps((left + right) / 2, (top + bottom) / 2, reference_points, img_width, img_height)\n",
    "\n",
    "        # Append detection details\n",
    "        detections.append((classname, score, distance, gps_coords))\n",
    "\n",
    "        if classname in colorcodes.keys():\n",
    "            color = colorcodes[classname]\n",
    "        else:\n",
    "            c1 = random.randrange(0, 255, 30)\n",
    "            c2 = random.randrange(0, 255, 25)\n",
    "            c3 = random.randrange(0, 255, 50)\n",
    "            colorcodes.update({classname: (c1, c2, c3)})\n",
    "            color = colorcodes[classname]\n",
    "\n",
    "        namewithscore = \"{}:{}\".format(classname, int(100 * score))\n",
    "        drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color, distance)\n",
    "\n",
    "    return image, detections\n",
    "\n",
    "# Initialize webcam input\n",
    "#video_path = r\"C:\\Users\\Sami\\Downloads\\videoplayback.mp4\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Get the original frame dimensions of the video\n",
    "original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Create an empty DataFrame to store detections\n",
    "df = pd.DataFrame(columns=[\"Time\", \"Class\", \"Score\", \"Distance (m)\", \"GPS Coordinates (lat, lon)\"])\n",
    "\n",
    "# Start processing the video\n",
    "try:\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        start_time = time.time()  # Record the start time of the loop\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Skip frames to improve performance (process every 3rd frame)\n",
    "        frame_count += 1\n",
    "        if frame_count % 3 != 0:\n",
    "            continue\n",
    "\n",
    "        # Convert the frame to RGB format and normalize it for model input\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        converted_img = tf.image.convert_image_dtype(frame_rgb, tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "        # Perform detection\n",
    "        detection = model(converted_img)\n",
    "        result = {key: value.numpy() for key, value in detection.items()}\n",
    "\n",
    "        # Draw bounding boxes and get detections\n",
    "        frame_with_boxes, detections = draw(frame, result['detection_boxes'], result['detection_class_entities'], result[\"detection_scores\"], original_width, original_height)\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        cv2.imshow('Video Object Detection', cv2.resize(frame_with_boxes, (original_width, original_height)))\n",
    "\n",
    "        # Save detections into DataFrame\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        if detections:\n",
    "            new_rows = pd.DataFrame([(current_time, classname, score, dist, gps) for classname, score, dist, gps in detections], \n",
    "                                    columns=[\"Time\", \"Class\", \"Score\", \"Distance (m)\", \"GPS Coordinates (lat, lon)\"])\n",
    "            df = pd.concat([df, new_rows], ignore_index=True)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Cap the frame rate to 10 FPS (0.1s per frame)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time < 0.1:  # If processing took less than 0.1 seconds, wait for the remaining time\n",
    "            time.sleep(0.1 - elapsed_time)\n",
    "\n",
    "finally:\n",
    "    # Release the video and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the detections to an Excel file\n",
    "    df.to_excel(\"detections_with_gps.xlsx\", index=False)\n",
    "    print(\"Detections saved to detections_with_gps.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
