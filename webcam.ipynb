{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002ddf3-1e36-4c11-86f2-17f70cb04899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "# Load the model\n",
    "model = hub.load(\"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow1/openimages-v4-ssd-mobilenet-v2/1\").signatures[\"default\"]\n",
    "\n",
    "# Define the target classes to detect\n",
    "target_classes = []\n",
    "\n",
    "# Initialize a dictionary to store color codes\n",
    "colorcodes = {}\n",
    "\n",
    "# Initialize a list to store detection data\n",
    "detections_data = []\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color):\n",
    "    im_height, im_width, _ = image.shape\n",
    "    left, top, right, bottom = int(xmin * im_width), int(ymin * im_height), int(xmax * im_width), int(ymax * im_height)\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), color=color, thickness=2)\n",
    "\n",
    "    FONT_SCALE = 0.5\n",
    "    THICKNESS_SCALE = 1\n",
    "    TEXT_Y_OFFSET_SCALE = 0.01\n",
    "\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (left, top - int(20)),\n",
    "        (right, top),\n",
    "        color=color,\n",
    "        thickness=-1\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        namewithscore,\n",
    "        (left, top - int(5)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=FONT_SCALE,\n",
    "        thickness=THICKNESS_SCALE,\n",
    "        color=(255, 255, 255)\n",
    "    )\n",
    "\n",
    "# Function to process detections and draw them on the image\n",
    "def draw(image, boxes, classnames, scores):\n",
    "    global detections_data\n",
    "    boxesidx = tf.image.non_max_suppression(boxes, scores, max_output_size=10, iou_threshold=0.4, score_threshold=0.3)\n",
    "\n",
    "    for i in boxesidx:\n",
    "        ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "        classname = classnames[i].decode(\"ascii\")\n",
    "\n",
    "        if classname in target_classes:\n",
    "            if classname in colorcodes.keys():\n",
    "                color = colorcodes[classname]\n",
    "            else:\n",
    "                c1 = random.randrange(0, 255, 30)\n",
    "                c2 = random.randrange(0, 255, 25)\n",
    "                c3 = random.randrange(0, 255, 50)\n",
    "                colorcodes.update({classname: (c1, c2, c3)})\n",
    "                color = colorcodes[classname]\n",
    "\n",
    "            namewithscore = \"{}:{}\".format(classname, int(100 * scores[i]))\n",
    "            drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color)\n",
    "\n",
    "            # Store detection data\n",
    "            detections_data.append({\n",
    "                \"Class\": classname,\n",
    "                \"Confidence Score\": scores[i],\n",
    "                \"ymin\": ymin,\n",
    "                \"xmin\": xmin,\n",
    "                \"ymax\": ymax,\n",
    "                \"xmax\": xmax\n",
    "            })\n",
    "\n",
    "    return image\n",
    "\n",
    "# Real-time object detection\n",
    "def detect_objects_in_real_time():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width = 400, 400\n",
    "        frame = cv2.resize(frame, (width, height))\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        converted_img = tf.image.convert_image_dtype(image_rgb, tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "        detection = model(converted_img)\n",
    "        result = {key: value.numpy() for key, value in detection.items()}\n",
    "\n",
    "        image_with_boxes = draw(frame, result['detection_boxes'], result['detection_class_entities'], result[\"detection_scores\"])\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        _, encoded_image = cv2.imencode('.jpg', image_with_boxes)\n",
    "        display(Image(data=encoded_image))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save detections to Excel file\n",
    "    df = pd.DataFrame(detections_data)\n",
    "    df.to_excel(\"detections.xlsx\", index=False)\n",
    "    print(\"Detections saved to detections.xlsx\")\n",
    "\n",
    "# Run the real-time object detection\n",
    "detect_objects_in_real_time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4792ca00-24da-4c45-a003-8a7874062a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "C:\\Users\\Sami\\AppData\\Local\\Temp\\ipykernel_19176\\4246426242.py:105: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_rows], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detections saved to detections.xlsx\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time  # Import time module\n",
    "\n",
    "# Load the model\n",
    "model = hub.load(\"https://www.kaggle.com/models/google/mobilenet-v2/TensorFlow1/openimages-v4-ssd-mobilenet-v2/1\").signatures[\"default\"]\n",
    "\n",
    "# Initialize a dictionary to store color codes\n",
    "colorcodes = {}\n",
    "\n",
    "# Function to draw bounding boxes\n",
    "def drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color):\n",
    "    im_height, im_width, _ = image.shape\n",
    "    left, top, right, bottom = int(xmin * im_width), int(ymin * im_height), int(xmax * im_width), int(ymax * im_height)\n",
    "    cv2.rectangle(image, (left, top), (right, bottom), color=color, thickness=2)\n",
    "\n",
    "    FONT_SCALE = 0.5\n",
    "    THICKNESS_SCALE = 1\n",
    "    TEXT_Y_OFFSET_SCALE = 0.01\n",
    "\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (left, top - int(20)),\n",
    "        (right, top),\n",
    "        color=color,\n",
    "        thickness=-1\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        namewithscore,\n",
    "        (left, top - int(5)),\n",
    "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        fontScale=FONT_SCALE,\n",
    "        thickness=THICKNESS_SCALE,\n",
    "        color=(255, 255, 255)\n",
    "    )\n",
    "\n",
    "# Function to process detections and draw them on the image\n",
    "def draw(image, boxes, classnames, scores):\n",
    "    # Filter detections based on scores\n",
    "    boxesidx = tf.image.non_max_suppression(boxes, scores, max_output_size=10, iou_threshold=0.4, score_threshold=0.3)\n",
    "    detections = []\n",
    "\n",
    "    for i in boxesidx:\n",
    "        ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "        classname = classnames[i].decode(\"ascii\")\n",
    "        score = scores[i]\n",
    "        detections.append((classname, score))\n",
    "\n",
    "        if classname in colorcodes.keys():\n",
    "            color = colorcodes[classname]\n",
    "        else:\n",
    "            c1 = random.randrange(0, 255, 30)\n",
    "            c2 = random.randrange(0, 255, 25)\n",
    "            c3 = random.randrange(0, 255, 50)\n",
    "            colorcodes.update({classname: (c1, c2, c3)})\n",
    "            color = colorcodes[classname]\n",
    "\n",
    "        namewithscore = \"{}:{}\".format(classname, int(100 * score))\n",
    "        drawbox(image, ymin, xmin, ymax, xmax, namewithscore, color)\n",
    "\n",
    "    return image, detections\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create an empty DataFrame to store detections\n",
    "df = pd.DataFrame(columns=[\"Time\", \"Class\", \"Score\"])\n",
    "\n",
    "# Start the webcam feed\n",
    "try:\n",
    "    while True:\n",
    "        start_time = time.time()  # Record the start time of the loop\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize the frame for consistent processing\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        converted_img = tf.image.convert_image_dtype(frame_rgb, tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "        # Perform detection\n",
    "        detection = model(converted_img)\n",
    "        result = {key: value.numpy() for key, value in detection.items()}\n",
    "\n",
    "        # Draw bounding boxes and get detections\n",
    "        frame_with_boxes, detections = draw(frame, result['detection_boxes'], result['detection_class_entities'], result[\"detection_scores\"])\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        cv2.imshow('Real-time Object Detection', frame_with_boxes)\n",
    "\n",
    "        # Save detections into DataFrame\n",
    "        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        if detections:\n",
    "            new_rows = pd.DataFrame([(current_time, classname, score) for classname, score in detections], columns=[\"Time\", \"Class\", \"Score\"])\n",
    "            df = pd.concat([df, new_rows], ignore_index=True)\n",
    "\n",
    "        # Press 'q' to exit the loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Ensure the loop runs only twice per second\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time < 0.5:  # If processing took less than 0.5 seconds, wait for the remaining time\n",
    "            time.sleep(0.5 - elapsed_time)\n",
    "\n",
    "finally:\n",
    "    # Release the webcam and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Save the detections to an Excel file\n",
    "    df.to_excel(\"detections.xlsx\", index=False)\n",
    "    print(\"Detections saved to detections.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3929b38-601c-4236-a959-40fb9bc78551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
